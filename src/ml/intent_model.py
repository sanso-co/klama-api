# src/ml/intent_model.py
import os
import joblib
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report


class DramaIntentClassifier:
    """
    ê°ì •(emotion) + ì§ˆë¬¸(question) í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•´ intentë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¶„ë¥˜ê¸°.
    - í¬ì†Œ í´ë˜ìŠ¤(drop/other) ì²˜ë¦¬
    - TF-IDF(1~2gram) + LogisticRegression
    - models/ ì— model/vectorizer/label_encoder ì €ì¥/ë¡œë“œ
    """

    def __init__(self, min_count: int = 2, rare_strategy: str = "drop", other_label: str = "other"):
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            stop_words="english",
            lowercase=True,
        )
        self.label_encoder = LabelEncoder()
        self.model = LogisticRegression(random_state=42, max_iter=1000, C=1.0)
        self.min_count = min_count
        self.rare_strategy = rare_strategy
        self.other_label = other_label
        self.data: pd.DataFrame | None = None

    def load_data(self, csv_path: str = "data/intent_training_data.csv") -> pd.DataFrame | None:
        """
        CSV ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        - csv_path: 'data/intent_training_data.csv' ê°™ì€ ìƒëŒ€ê²½ë¡œë‚˜ ì ˆëŒ€ê²½ë¡œ ëª¨ë‘ í—ˆìš©
        - ìƒëŒ€ê²½ë¡œë©´ ì´ íŒŒì¼(src/ml) ê¸°ì¤€ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ í•©ì„±
        """
        base_dir = os.path.dirname(__file__)  # src/ml
        full_path = csv_path if os.path.isabs(
            csv_path) else os.path.join(base_dir, csv_path)

        try:
            df = pd.read_csv(full_path)

            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required = ["emotion", "question", "intent"]
            missing = [c for c in required if c not in df.columns]
            if missing:
                raise ValueError(
                    f"CSVì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing} / ì‹¤ì œ ì»¬ëŸ¼: {list(df.columns)}"
                )

            # ê²°ì¸¡ì¹˜ ì œê±° ë° ë¬¸ìì—´ í´ë¦°ì—…
            df = df.dropna(subset=required).copy()
            for col in required:
                df[col] = df[col].astype(str).str.strip()

            # ì™„ì „ ê³µë°± í–‰ ì œê±°(ì„ íƒ)
            for col in required:
                df = df[df[col].str.len() > 0]

            self.data = df.reset_index(drop=True)
            return self.data

        except FileNotFoundError:
            print(f"[ERROR] CSV not found: {full_path}")
            return None

    def _handle_rare_classes(self) -> None:
        """ìƒ˜í”Œ ìˆ˜ê°€ min_count ë¯¸ë§Œì¸ intentë¥¼ ì œê±°(drop)í•˜ê±°ë‚˜ otherë¡œ ë³‘í•©"""
        if self.data is None:
            return
        vc = self.data["intent"].value_counts()
        rare = vc[vc < self.min_count].index.tolist()
        if not rare:
            return
        if self.rare_strategy == "drop":
            self.data = self.data[~self.data["intent"].isin(
                rare)].reset_index(drop=True)
        elif self.rare_strategy == "other":
            self.data["intent"] = self.data["intent"].where(
                ~self.data["intent"].isin(rare), self.other_label
            )

    def _prepare_text_and_labels(self, fit_label_encoder: bool = True):
        """emotion + question ê²°í•© í…ìŠ¤íŠ¸ ìƒì„± ë° ë ˆì´ë¸” ì¸ì½”ë”©"""
        if self.data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        combined = (
            self.data["emotion"].fillna(
                "") + " " + self.data["question"].fillna("")
        ).str.strip()
        if fit_label_encoder:
            y = self.label_encoder.fit_transform(self.data["intent"])
        else:
            y = self.label_encoder.transform(self.data["intent"])
        return combined, y

    def train(self, test_size: float = 0.2) -> dict:
        """ëª¨ë¸ í•™ìŠµ ë° ê°„ë‹¨ ë¦¬í¬íŠ¸ ë°˜í™˜"""
        if self.data is None or len(self.data) == 0:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € load_data()ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        # í¬ì†Œ í´ë˜ìŠ¤ ì²˜ë¦¬
        self._handle_rare_classes()

        # í…ìŠ¤íŠ¸/ë¼ë²¨ ì¤€ë¹„
        text, y = self._prepare_text_and_labels(fit_label_encoder=True)

        # train/test ë¶„í• 
        from sklearn.model_selection import train_test_split  # ì§€ì—° import
        X_tr_text, X_te_text, y_tr, y_te = train_test_split(
            text, y, test_size=test_size, random_state=42, stratify=y
        )

        # ë²¡í„°í™”: train fit / test transform (ë°ì´í„° ìœ ì¶œ ë°©ì§€)
        X_tr = self.vectorizer.fit_transform(X_tr_text)
        X_te = self.vectorizer.transform(X_te_text)

        # í•™ìŠµ
        self.model.fit(X_tr, y_tr)

        # ì„±ëŠ¥
        train_acc = self.model.score(X_tr, y_tr)
        test_acc = self.model.score(X_te, y_te)
        y_pred = self.model.predict(X_te)
        report = classification_report(
            y_te,
            y_pred,
            labels=np.arange(len(self.label_encoder.classes_)),  # ğŸ”¹ í´ë˜ìŠ¤ ê°œìˆ˜ ëª…ì‹œ
            target_names=self.label_encoder.classes_,
            zero_division=0,
        )

        return {"train_acc": train_acc, "test_acc": test_acc, "report": report}

    def save(self, model_dir: str = "models") -> None:
        """í•™ìŠµëœ ëª¨ë¸/ì „ì²˜ë¦¬ê¸° ì €ì¥"""
        os.makedirs(model_dir, exist_ok=True)
        joblib.dump(self.model, os.path.join(model_dir, "intent_model.pkl"))
        joblib.dump(self.vectorizer, os.path.join(model_dir, "vectorizer.pkl"))
        joblib.dump(self.label_encoder, os.path.join(
            model_dir, "label_encoder.pkl"))

    def load(self, model_dir: str = "models") -> bool:
        """ì €ì¥ëœ ëª¨ë¸/ì „ì²˜ë¦¬ê¸° ë¡œë“œ"""
        self.model = joblib.load(os.path.join(model_dir, "intent_model.pkl"))
        self.vectorizer = joblib.load(
            os.path.join(model_dir, "vectorizer.pkl"))
        self.label_encoder = joblib.load(
            os.path.join(model_dir, "label_encoder.pkl"))
        return True

    def predict_topk(self, question: str, feeling: str = "", top_k: int = 2) -> dict:
        """ìƒˆ ì¸í’‹ì— ëŒ€í•´ Top-K intentì™€ confidence ë°˜í™˜"""
        combined = f"{feeling} {question}".strip()
        vec = self.vectorizer.transform([combined])
        proba = self.model.predict_proba(vec)[0]
        idxs = np.argsort(proba)[::-1][:top_k]
        results = [
            {"intent": self.label_encoder.classes_[
                i], "confidence": float(proba[i])}
            for i in idxs
        ]
        return {
            "input": combined,
            "top_predictions": results,
        }


def predict_drama_intent(question: str, feeling: str = "", model_dir: str = "models", top_k: int = 3) -> dict:
    """ì¶”ë¡ ìš© í—¬í¼ (APIì—ì„œ ë°”ë¡œ í˜¸ì¶œ ê°€ëŠ¥)"""
    clf = DramaIntentClassifier()
    clf.load(model_dir=model_dir)
    return clf.predict_topk(question=question, feeling=feeling, top_k=top_k)
